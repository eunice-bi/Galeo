{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_in_excel(filename, df):\n",
    "    writer = pd.ExcelWriter(filename)\n",
    "    df.to_excel(writer,\"Sheet\",index = True) \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the correlation between a feature and the target\n",
    "def get_correlation_target(df,index_column,target):\n",
    "    return stats.pearsonr(df.iloc[:,index_column],target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of adresses in regards of a column name\n",
    "def get_list_adress_from_columns(df,list_columns):\n",
    "    list_adress = df.iloc[-2,:]\n",
    "    list_adress.index = range(len(list_adress))\n",
    "    for i, text in enumerate(list_adress):\n",
    "        if text == 0 or text == ' ' or pd.isna(text)==True :\n",
    "            list_adress[i] = list_columns[i]\n",
    "    list_adress.index = list_columns \n",
    "    return list_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data frame by removing Date, getting the list of columns and adresses \n",
    "def prepare_df_to_get_correlations(df,bool_validation):\n",
    "    df = df.drop(columns='Date')\n",
    "    df.columns = range(len(df.columns))\n",
    "    list_columns = df.iloc[-3,:]\n",
    "    #list_columns.index = range(len(list_columns))\n",
    "    #list_columns = list_columns.reset_index(drop=True,inplace=False)\n",
    "    size = len(list_columns)\n",
    "    list_columns.update(pd.Series(['WEEKDAYS', 'MONTHS','QUARTERS','Energie'], index=[size-4, size-3,size-2,size-1]))\n",
    "    if(bool_validation == 0):\n",
    "        list_adress = get_list_adress_from_columns(df,list_columns)\n",
    "    df.columns = range(len(df.columns))\n",
    "    df = df.iloc[:-3,:]\n",
    "    df_energie = df.iloc[:,-1]\n",
    "    df_energie_kw = df_energie/0.25\n",
    "    df.iloc[:,-1] = df_energie_kw\n",
    "    df.Energie = df_energie_kw \n",
    "    if(bool_validation == 0):\n",
    "        return df, list_adress, list_columns\n",
    "    else :\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of the data frame\n",
    "def normalization(df):\n",
    "    scaler.fit(df)\n",
    "    return pd.DataFrame(scaler.transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the time step of the data frame\n",
    "def df_changed_time_step(df,step_in_15minutes):\n",
    "    df_changed_time_step = pd.DataFrame(df.iloc[0:step_in_15minutes].median(axis=0)).transpose()\n",
    "    for i in range(1,int(len(df.index)/step_in_15minutes)):\n",
    "        df_changed_time_step.loc[i] = (df.iloc[step_in_15minutes*i:step_in_15minutes*(i+1)].median(axis=0)).transpose()\n",
    "    df_norm_changed_time_step = normalization(df_changed_time_step)\n",
    "    return df_norm_changed_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Energie_median(df,step_in_15minutes):\n",
    "    list_energie = [df.iloc[:,-1][1:step_in_15minutes].median()]\n",
    "    for i in range(1,int(len(df.index)/step_in_15minutes)):\n",
    "        list_energie.append(df.iloc[:,-1][step_in_15minutes*i:step_in_15minutes*(i+1)].median())\n",
    "    return list_energie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_correlation_matrix(df,target,correlation_level):\n",
    "    list_correlations = [get_correlation_target(df,i,target) for i in range(len(df.columns))]\n",
    "    df_correlations = pd.DataFrame([list_correlations],columns=list_columns[:-1]).transpose()\n",
    "    df_correlations.columns = ['Corrélation avec Energie totale']\n",
    "    df_correlations[\"Texte\"] = list_adress[:-1]\n",
    "    df_correlations_correlation_level = df_correlations[abs(df_correlations['Corrélation avec Energie totale'])>correlation_level]\n",
    "    return df_correlations_correlation_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_correlation_matrix_after_first_matrix(df_corr,target,correlation_level):\n",
    "    list_correlations = [get_correlation_target(df_corr,i,target) for i in range(len(df_corr.columns))]\n",
    "    df_correlations = pd.DataFrame([list_correlations],columns=df_corr.columns).transpose()\n",
    "    df_correlations.columns = ['Corrélation avec Energie totale']\n",
    "    df_correlations[\"Texte\"] = list_adress[:-1]\n",
    "    df_correlations_correlation_level = df_correlations[abs(df_correlations['Corrélation avec Energie totale'])>correlation_level]\n",
    "    return df_correlations_correlation_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_correlations(df,target,name,correlation_level):\n",
    "    #list_columns = list_columns.tolist()\n",
    "    df_correlations_correlation_level = build_correlation_matrix(df,target,correlation_level)\n",
    "    name_columns_correlations_correlation_level = df_correlations_correlation_level.index.values.tolist() \n",
    "    list_columns_str = str(list_columns)\n",
    "    df_columns = pd.DataFrame(list_columns)\n",
    "    #list_columns = list_columns.reset_index(drop=True,inplace=False)\n",
    "    list_index = [df_columns.index[df_columns[\"Adress\"] == val][0] for val in name_columns_correlations_correlation_level]\n",
    "    pickle.dump(df , open( name+\".p\", \"wb\" ) )\n",
    "    pickle.dump(df.Energie , open( \"target\"+name+\".p\", \"wb\" ) )\n",
    "    name_corr = name + \"_corr.p\"\n",
    "    name_index =  \"list_index_\"+name+\".p\"\n",
    "    pickle.dump(df_correlations_correlation_level, open(name_corr, \"wb\" ) )\n",
    "    pickle.dump(list_index, open( name_index, \"wb\" ) )\n",
    "    return df_correlations_correlation_level, list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_without_duplicates(myList):\n",
    "    y = list(set(myList))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_much_correlations(df_norm,df_corr,list_text,list_index_corr,num,var):\n",
    "    list_text_corr = list_text[list_index_corr]\n",
    "    df_norm_just_corr = df_norm.iloc[:,list_index_corr]\n",
    "    df_norm_just_corr.columns = range(len(df_norm_just_corr.columns))\n",
    "    df_norm_just_corr.index = range(len(df_norm_just_corr.index))\n",
    "    list_correlation = np.full((num, num), 0.00000)\n",
    "    for j in range(len(var)-1):\n",
    "        for i in range(len(df_norm_just_corr.columns)-1):\n",
    "            list_correlation[j][i]=get_correlation_target(df_norm_just_corr,i,df_norm_just_corr.iloc[:,j])\n",
    "    df_correlations = pd.DataFrame(list_correlation)\n",
    "    df_correlations[df_correlations==1]=-1\n",
    "    list_max_correlations = df_correlations.max(axis=1).tolist()\n",
    "    #test = df_correlations.iloc[:,i].values\n",
    "    list_index_max = []\n",
    "    for i, max_i in enumerate(list_max_correlations):\n",
    "        test = list(df_correlations.iloc[:,i].values)\n",
    "        list_index_max.append(test.index(max_i))\n",
    "    list_index_max_couples = np.full((num, 2),0)\n",
    "    for i in range(0,len(var)):\n",
    "        list_index_max_couples[i][0] = i\n",
    "    for i in range(0,len(var)):\n",
    "        list_index_max_couples[i][1] = list_index_max[i]\n",
    "    list_to_delete = []\n",
    "    for i in range(1,len(df_corr)-1):\n",
    "        for j in range(i+1,len(df_corr.columns)):\n",
    "            if(list_index_max_couples[i][0] == list_index_max_couples[j][1]):\n",
    "                list_to_delete.append(j)\n",
    "    list_index_max_couples = np.delete(list_index_max_couples,list_to_delete,axis=0)\n",
    "    list_index_to_keep = []\n",
    "    for i in range(0,len(list_index_max_couples)):\n",
    "        if(df_corr.iloc[list_index_max_couples[i][0],0]>df_corr.iloc[list_index_max_couples[i][1],0]):\n",
    "            list_index_to_keep.append(list_index_max_couples[i][0])\n",
    "        else :\n",
    "            list_index_to_keep.append(list_index_max_couples[i][1])\n",
    "    df_corr_corr = df_corr.iloc[list_index_to_keep]\n",
    "    df_norm_just_corr = df_norm_just_corr.iloc[:,list_index_to_keep]\n",
    "    bb = sorted(list_index_to_keep)\n",
    "    list_index_corr_to_keep = [list_index_corr[val]for val in bb]\n",
    "    list_text_corr_corr = list_text_corr[list_index_to_keep]\n",
    "    df_norm_just_corr = pd.DataFrame(df_norm_just_corr,columns = list_index_to_keep)\n",
    "    df_norm_just_corr.columns = list_text_corr_corr\n",
    "    df_norm_just_corr = df_norm_just_corr.astype(float)\n",
    "    df_norm_just_corr = df_norm_just_corr.transpose().drop_duplicates().transpose()\n",
    "    list_index_corr_to_keep = list_without_duplicates(list_index_corr_to_keep)\n",
    "    return df_norm_just_corr, list_index_corr_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twice_corr(df_norm,df_corr,list_text,list_index_corr):\n",
    "    a,b = remove_too_much_correlations(df_norm,df_corr,list_text,list_index_corr,len(df_corr),df_corr)\n",
    "    c,d = remove_too_much_correlations(df_norm,a,list_text,b,len(a.columns),a.columns)\n",
    "    return c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twice_corr_once(df_norm,df_corr,list_text,list_index_corr):\n",
    "    a,b = remove_too_much_correlations(df_norm,df_corr,list_text,list_index_corr,len(df_corr),df_corr)\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_of_EDA(df,df_Energie,name):\n",
    "    pickle.dump(df , open( \"X_\"+name+\".p\", \"wb\" ) )\n",
    "    pickle.dump(df_Energie , open( \"y_\"+name+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_df_with_different_steps(df):\n",
    "    df_norm = normalization(df)\n",
    "    df_norm = df_norm.iloc[:,:-1]\n",
    "    df_norm.Energie = df.iloc[:,-1]\n",
    "    pickle.dump(df_norm , open( \"data_norm.p\", \"wb\" ) )\n",
    "    pickle.dump(df_norm.Energie , open( \"target.p\", \"wb\" ) )\n",
    "    df_norm_hour = df_changed_time_step(df.iloc[:,:-1],4)\n",
    "    df_norm_6_hour = df_changed_time_step(df.iloc[:,:-1],24) \n",
    "    df_norm_day = df_changed_time_step(df.iloc[:,:-1],96)\n",
    "\n",
    "    df_norm_week = df_changed_time_step(df.iloc[96*5:,:-1],96*7)\n",
    "\n",
    "\n",
    "    df_norm_hour.Energie = add_Energie_median(df,4)\n",
    "    df_norm_6_hour.Energie = add_Energie_median(df,24)\n",
    "    df_norm_day.Energie = add_Energie_median(df,96)\n",
    "    df_norm_week.Energie = add_Energie_median(df.iloc[96*5:],96*7)\n",
    "    return df_norm, df_norm_hour,df_norm_6_hour,df_norm_day,df_norm_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_statistics(df_norm, df_norm_hour,df_norm_6_hour,df_norm_day,df_norm_week):\n",
    "    df_corr_15_min, list_index_corr_15_min = launch_correlations(df_norm,df_norm.Energie,\"15_min\",0.7)\n",
    "    df_corr_hour, list_index_corr_hour = launch_correlations(df_norm_hour,df_norm_hour.Energie,\"hour\",0.7)\n",
    "    df_corr_6_hour, list_index_corr_6_hour = launch_correlations(df_norm_6_hour,df_norm_6_hour.Energie,\"6_hour\",0.7)\n",
    "    df_corr_day, list_index_corr_day = launch_correlations(df_norm_day,df_norm_day.Energie,\"day\",0.7)\n",
    "    df_corr_week, list_index_corr_week = launch_correlations(df_norm_week,df_norm_week.Energie,\"week\",0.8)\n",
    "\n",
    "    df_15_min, index_15_min = twice_corr(df_norm,df_corr_15_min,list_adress,list_index_corr_15_min)\n",
    "    df_hour,index_hour = twice_corr(df_norm_hour,df_corr_hour,list_adress,list_index_corr_hour)\n",
    "    df_6_hour,index_6_hour = twice_corr(df_norm_6_hour,df_corr_6_hour,list_adress,list_index_corr_6_hour)\n",
    "    df_day,index_day = twice_corr(df_norm_day,df_corr_day,list_adress,list_index_corr_day)\n",
    "    df_week,index_week = twice_corr_once(df_norm_week,df_corr_week,list_adress,list_index_corr_week)\n",
    "\n",
    "    df_corr_week2 = build_correlation_matrix_after_first_matrix(df_week,df_norm_week.Energie,0.7)\n",
    "\n",
    "    df_week2,index_week2 = twice_corr_once(df_norm_week,df_corr_week2,list_adress,index_week)\n",
    "    \n",
    "    return df_15_min, df_hour,df_6_hour,df_day,df_week2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_EDA(df,name):\n",
    "    df_norm, df_norm_hour,df_norm_6_hour,df_norm_day,df_norm_week = get_normalized_df_with_different_steps(df)\n",
    "    df_15_min, df_hour,df_6_hour,df_day,df_week =  get_data_from_statistics(df_norm, df_norm_hour,df_norm_6_hour,df_norm_day,df_norm_week)\n",
    "    save_results_of_EDA(df_15_min,df_norm.Energie,name+\"15_min\")\n",
    "    save_results_of_EDA(df_hour,df_norm_hour.Energie,name+\"hour\")\n",
    "    save_results_of_EDA(df_6_hour,df_norm_6_hour.Energie,name+\"6_hour\")\n",
    "    save_results_of_EDA(df_day,df_norm_day.Energie,name+\"day\")\n",
    "    save_results_of_EDA(df_week,df_norm_week.Energie,name+\"week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"data_total_prepared.p\", \"rb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "df,list_adress,list_columns = prepare_df_to_get_correlations(df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n",
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "launch_EDA(df,'learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pickle.load(open(\"data_validation_total_prepared.p\", \"rb\") )\n",
    "#df_validation = prepare_df_to_get_correlations(df_validation,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOREAU Simon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "df_validation = prepare_df_to_get_correlations(df_validation,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch_EDA(df,'validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
